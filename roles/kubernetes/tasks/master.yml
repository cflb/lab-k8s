---
## this will be executed only on the first master

- name: print vars
  debug:
    msg:
    - "The inventory hostname is {{ inventory_hostname }}"
    - "The kubernetes master is {{ kubernetes_master }} and port is {{ kubernetes_apiserver_port }}"

- name: Checking if master is running
  wait_for:
      host: "{{ kubernetes_master }}"
#      port: 22
      port: "{{ kubernetes_apiserver_port }}"
      delay: 15
      timeout: 60
      state: started
      msg: "Kubernetes still not Listening"
  ignore_errors: true
  register: kubernetes_is_bootstrapped

- name: Fail if the Master node is already bootstrapped
  fail: msg="Master node is already bootstrapped"
  when: kubernetes_is_bootstrapped.changed

- name: master - kubeadm - init the cluster
  shell: "kubeadm init --control-plane-endpoint='{{ kubernetes_master }}:6443' --apiserver-advertise-address='{{ kubernetes_master }}' --pod-network-cidr='10.2.0.0/16' --upload-certs --cri-socket /run/containerd/containerd.sock --skip-phases=addon/coredns"
  register: kubernetes_result
  when: kubernetes_result is not defined and inventory_hostname in groups['master_root']

- name: master - check if the result code of last task was true
  fail: msg="kubeadm init failed and we can't proceed, please check inside the machine."
  when: kubernetes_result.rc != 0

- name: master - copying calico.yaml
  copy:
    src: calico_v3.26.yaml
    dest: /root/calico.yaml
    owner: root
    group: root
    mode: '0644'

- name: master - kubectl - applying Calico to deal with the network
  shell: kubectl --kubeconfig=/etc/kubernetes/admin.conf apply -f /root/calico.yaml
  register: kubernetes_calico
  when: kubernetes_calico is not defined and inventory_hostname in groups['master_root']


# - name: master - kubeadm - create token for workers
#   shell: "kubeadm token create --print-join-command 2>/dev/null"
#   register: kubernetes_join_cmd
#   when: inventory_hostname in groups['master_root']
# 
# - name: master - kubeadm - set_fact kubernetes_join
#   local_action: copy content="{{ kubernetes_join_cmd.stdout }}" dest="/tmp/kubernetes_token"
#   when: inventory_hostname in groups['master_root']
# 
# - name: master - kubeadm - get certificate key for another master
#   shell: "kubeadm certs certificate-key 2>/dev/null"
#   register: kubernetes_certificate_key
#   when: inventory_hostname in groups['master_root']
# 
# - name: master - kubeadm - create token for a new master
#   shell: "kubeadm token create --print-join-command --certificate-key {{ kubernetes_certificate_key.stdout }} 2>/dev/null"
#   register: kubernetes_join_cmd_master
#   when: inventory_hostname in groups['master_root']
# 
# - name: master - kubeadm - set_fact kubernetes_join
#   local_action: copy content="{{ kubernetes_join_cmd_master.stdout }}" dest="/tmp/kubernetes_token_master"
#   when: inventory_hostname in groups['master_root']

## this only executes on the other masters if they exist

#- name: master - waiting for master is up
#  wait_for:
#      host: "{{ kubernetes_master }}"
#      port: "{{ kubernetes_apiserver_port }}"
#      delay: 15
#      timeout: 600
#      state: started
#      msg: "Kubernetes still not Listening"
#  ignore_errors: true
#  when: inventory_hostname in groups['masters'] and inventory_hostname not in groups['master_root']
#
#- name: master - copy join command to nodes
#  local_action: copy src="/tmp/kubernetes_token_master" dest="/tmp/kubernetes_token_master"
#  when: inventory_hostname in groups['masters'] and inventory_hostname not in groups['master_root']
#
#- name: master - kubeadm - join this node on the cluster
#  vars:
#    kubernetes_join: "{{ lookup('file', '/tmp/kubernetes_token_master') }}"
#  shell: "{{ kubernetes_join }}"
#  when: inventory_hostname in groups['masters'] and inventory_hostname not in groups['master_root']
#
#- name: master - kubectl - untaint master nodes to schedule pods on them
#  shell: kubectl --kubeconfig=/etc/kubernetes/admin.conf taint node --all node-role.kubernetes.io/master:NoSchedule-
#  when: inventory_hostname in groups['masters']
#
